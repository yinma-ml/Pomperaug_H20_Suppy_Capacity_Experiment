{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# author: Yin \n",
    "# 08 13 simulation prediction, do not use panel feature\n",
    "#4 27 2020, change panel identifier from id to csid, get identical results as LG\n",
    "# 05 04 2020 edefine scaled utility model (0427 folder's model keep original starting values)\n",
    "# 05 05 test new scale starting values: all 0 except mu=5 as starting values give the best results  04logit_rrm~09.html\n",
    "# 05 05 also tested mu*(sum of covar) form, results are bad, plus not make sense: (1) can enlarge coeff w/o introducing mu;\n",
    "#       (2) hard to interpret mu and mu and other effects are confunded\n",
    "\n",
    "# RRM with panel data and scale variables\n",
    "# Three alternatives: sq,a,b; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import biogeme.database as db\n",
    "import biogeme.biogeme as bio\n",
    "import biogeme.models as models\n",
    "import biogeme.results as res\n",
    "from biogeme.expressions import *\n",
    "import biogeme.expressions as ex\n",
    "\n",
    "#import machine learning package\n",
    "from sklearn.metrics import make_scorer, confusion_matrix, classification_report,recall_score, f1_score, accuracy_score, precision_score\n",
    "from sklearn.model_selection import TimeSeriesSplit, KFold, ShuffleSplit, LeavePGroupsOut,StratifiedKFold, GroupShuffleSplit,GroupKFold, StratifiedShuffleSplit\n",
    "                                     \n",
    "                                     \n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "%matplotlib inline\n",
    "\n",
    "cmap_data = plt.cm.Paired\n",
    "cmap_cv = plt.cm.RdBu\n",
    "n_splits = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating confidence intervals for elasticities requires interval arithmetics \n",
    "#pip install python-intervals in anaconda prompt\n",
    "#in case python-intervals doesn't work, also install a newer version \"portion\"\n",
    "\n",
    "import portion as p\n",
    "import intervals as ivs\n",
    "import interval as iv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 03logit_rrm_0427.py...\n"
     ]
    }
   ],
   "source": [
    "print(\"Running 03logit_rrm_0427.py...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "df = pd.read_csv(\"agree0623_all_0427.csv\")\n",
    "database = db.Database(\"agree0623_all_0427\",df)\n",
    "# They are organized as panel data. The variable ID identifies each individual.\n",
    "#database.panel(\"csid\")\n",
    "# use the names of the variable as Python variable.\n",
    "globals().update(database.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7423.735097\n"
     ]
    }
   ],
   "source": [
    "# Normalize the weights\n",
    "sumWeight = database.data['weight'].sum()\n",
    "print(sumWeight) \n",
    "##result=7423.735097, sample size=7414"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizedWeight = weight * 7414 / 7423.735097\n",
    "# originally weight the whole sample use 1123 cases, \n",
    "# then delete nonresponse for choice questions, and 945 cases are used for logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to be estimated \n",
    "#NZone variables are already scaled: zone/100\n",
    "#use 0504~~06 biogeme rum estimates as starting values \n",
    "B_NZONE1 = Beta('B_NZONE1',-0.0445,None,None,0)\n",
    "B_NZONE2 = Beta('B_NZONE2',-0.0228,None,None,0)\n",
    "B_NZONE3 = Beta('B_NZONE3',-0.0216,None,None,0)\n",
    "B_TOWNDOWN = Beta('B_TOWNDOWN',0.005,None,None,0)\n",
    "B_TOWNMID = Beta('B_TOWNMID',0.0604,None,None,0)\n",
    "B_TOWNUP = Beta('B_TOWNUP',0.118,None,None,0)\n",
    "B_ECO = Beta('B_ECO',0.0353,None,None,0)\n",
    "B_REC = Beta('B_REC',0.0059,None,None,0)\n",
    "B_DRY = Beta('B_DRY',-0.124,None,None,0)\n",
    "B_TAX = Beta('B_TAX',-0.0157,None,None,0)\n",
    "\n",
    "# covariates for scales\n",
    "B_ASCEND = Beta('B_ASCEND',0,None,None,0)\n",
    "B_DESCEND = Beta('B_DESCEND',0,None,None,0)\n",
    "B_INCPP50K = Beta('B_INCPP50K',0,None,None,0)\n",
    "B_INCPP75K = Beta('B_INCPP75K',0,None,None,0)\n",
    "B_INCPP75KM = Beta('B_INCPP75KM',0,None,None,0)\n",
    "B_F1FLOW = Beta('B_F1FLOW',0,None,None,0)\n",
    "B_F3PROTUP = Beta('B_F3PROTUP',0,None,None,0)\n",
    "B_F4CTH2O = Beta('B_F4CTH2O',0,None,None,0)\n",
    "B_TAXGRT = Beta('B_TAXGRT',0,None,None,0)\n",
    "#test a few diff starting values, 5 is a good one\n",
    "mu    = Beta('mu',5,None,None,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the utility functions\n",
    "mu_scale = mu+ B_ASCEND*ascend+B_DESCEND*descend+B_INCPP50K*incpp_50k+B_INCPP75K*incpp_75k+B_INCPP75KM*incpp_75km+B_F1FLOW*f1_flow+B_F3PROTUP*f3_protup+B_F4CTH2O*f4_CTh2o+B_TAXGRT*taxgrt\n",
    "\n",
    "\n",
    "\n",
    "RSQ = mu_scale * (log( 1 + exp((B_NZONE1/mu_scale) * (nzone1_a-nzone1_sq))) + log(1 + exp((B_NZONE1/mu_scale ) * (nzone1_b-nzone1_sq))) + log(1 + exp((B_NZONE2/mu_scale) * (nzone2_a-nzone2_sq))) + log(1 + exp((B_NZONE2 / mu_scale ) * (nzone2_b-nzone2_sq))) + log(1 + exp((B_NZONE3 / mu_scale ) * (nzone3_a-nzone3_sq))) + log(1 + exp((B_NZONE3 / mu_scale ) * (nzone3_b-nzone3_sq))) + log( 1 + exp((B_TOWNDOWN / mu_scale ) * (towndown_a-towndown_sq))) + log(1 + exp((B_TOWNDOWN / mu_scale ) * (towndown_b-towndown_sq)))  + log(1 + exp((B_TOWNMID / mu_scale ) * (townmid_a-townmid_sq))) + log(1 + exp((B_TOWNMID / mu_scale ) * (townmid_b-townmid_sq))) + log(1 + exp((B_TOWNUP / mu_scale ) * (townup_a-townup_sq))) + log(1 + exp((B_TOWNUP / mu_scale ) * (townup_b-townup_sq))) + log( 1 + exp((B_ECO / mu_scale ) * (eco_a-eco_sq))) + log(1 + exp((B_ECO / mu_scale ) * (eco_b-eco_sq))) + log(1 + exp((B_REC / mu_scale ) * (rec_a-rec_sq))) + log(1 + exp((B_REC / mu_scale ) * (rec_b-rec_sq))) + log(1 + exp((B_DRY / mu_scale ) * (dry_a-dry_sq))) + log(1 + exp((B_DRY / mu_scale ) * (dry_b-dry_sq))) + log(1 + exp((B_TAX / mu_scale ) * (tax_a-tax_sq))) + log(1 + exp((B_TAX / mu_scale ) * (tax_b-tax_sq))))                                                \n",
    "          \n",
    "RA  = mu_scale * (log( 1 + exp((B_NZONE1/mu_scale) * (nzone1_sq-nzone1_a))) + log(1 + exp((B_NZONE1/mu_scale ) * (nzone1_b-nzone1_a))) + log(1 + exp((B_NZONE2/mu_scale) * (nzone2_sq-nzone2_a))) + log(1 + exp((B_NZONE2 / mu_scale ) * (nzone2_b-nzone2_a))) + log(1 + exp((B_NZONE3 / mu_scale ) * (nzone3_sq-nzone3_a))) + log(1 + exp((B_NZONE3 / mu_scale ) * (nzone3_b-nzone3_a))) + log( 1 + exp((B_TOWNDOWN / mu_scale ) * (towndown_sq-towndown_a))) + log(1 + exp((B_TOWNDOWN / mu_scale ) * (towndown_b-towndown_a))) + log(1 + exp((B_TOWNMID / mu_scale ) * (townmid_sq-townmid_a))) + log(1 + exp((B_TOWNMID / mu_scale ) * (townmid_b-townmid_a))) + log(1 + exp((B_TOWNUP / mu_scale ) * (townup_sq-townup_a))) + log(1 + exp((B_TOWNUP / mu_scale ) * (townup_b-townup_a))) + log( 1 + exp((B_ECO / mu_scale ) * (eco_sq-eco_a))) + log(1 + exp((B_ECO / mu_scale ) * (eco_b-eco_a))) + log(1 + exp((B_REC / mu_scale ) * (rec_sq-rec_a))) + log(1 + exp((B_REC / mu_scale ) * (rec_b-rec_a))) + log(1 + exp((B_DRY / mu_scale ) * (dry_sq-dry_a))) + log(1 + exp((B_DRY / mu_scale ) * (dry_b-dry_a))) + log(1 + exp((B_TAX / mu_scale ) * (tax_sq-tax_a))) + log(1 + exp((B_TAX / mu_scale ) * (tax_b-tax_a))))   \n",
    "           \n",
    "RB  = mu_scale * (log( 1 + exp((B_NZONE1/mu_scale) * (nzone1_sq-nzone1_b))) + log(1 + exp((B_NZONE1/mu_scale ) * (nzone1_a-nzone1_b))) + log(1 + exp((B_NZONE2/mu_scale) * (nzone2_sq-nzone2_b))) + log(1 + exp((B_NZONE2 / mu_scale ) * (nzone2_a-nzone2_b))) + log(1 + exp((B_NZONE3 / mu_scale ) * (nzone3_sq-nzone3_b))) + log(1 + exp((B_NZONE3 / mu_scale ) * (nzone3_a-nzone3_b))) + log( 1 + exp((B_TOWNDOWN / mu_scale ) * (towndown_sq-towndown_b))) + log(1 + exp((B_TOWNDOWN / mu_scale ) * (towndown_a-towndown_b))) + log(1 + exp((B_TOWNMID / mu_scale ) * (townmid_sq-townmid_b))) + log(1 + exp((B_TOWNMID / mu_scale ) * (townmid_a-townmid_b))) + log(1 + exp((B_TOWNUP / mu_scale ) * (townup_sq-townup_b))) + log(1 + exp((B_TOWNUP / mu_scale ) * (townup_a-townup_b))) + log( 1 + exp((B_ECO / mu_scale ) * (eco_sq-eco_b))) + log(1 + exp((B_ECO / mu_scale ) * (eco_a-eco_b))) + log(1 + exp((B_REC / mu_scale ) * (rec_sq-rec_b))) + log(1 + exp((B_REC / mu_scale ) * (rec_a-rec_b))) + log(1 + exp((B_DRY / mu_scale ) * (dry_sq-dry_b))) + log(1 + exp((B_DRY / mu_scale ) * (dry_a-dry_b))) + log(1 + exp((B_TAX / mu_scale ) * (tax_sq-tax_b))) + log(1 + exp((B_TAX / mu_scale ) * (tax_a-tax_b))))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associate utility functions with the numbering of alternatives\n",
    "V = {1: -RSQ,\n",
    "     2: -RA,\n",
    "     3: -RB}\n",
    "\n",
    "# Associate the availability conditions with the alternatives\n",
    "# all alternatives are available for each individual\n",
    "av = {1: 1,\n",
    "      2: 1,\n",
    "      3: 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the model. This is the contribution of each observation to the log likelihood function.\n",
    "logprob = models.loglogit(V,av,choice)\n",
    "prob_sq = models.logit(V,av,1)\n",
    "prob_a = models.logit(V,av,2)\n",
    "prob_b = models.logit(V,av,3)\n",
    "\n",
    "simulate = {'simprob_sq':prob_sq,\n",
    "            'simprob_a':prob_a,\n",
    "            'simprob_b':prob_b}\n",
    "\n",
    "\n",
    "\n",
    "biogeme  = bio.BIOGEME(database,simulate)\n",
    "biogeme.modelName = \"03logit_rrm_scale_simu_0813\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results=       simprob_sq  simprob_a  simprob_b\n",
      "0       0.215018   0.437310   0.347672\n",
      "1       0.217412   0.385622   0.396966\n",
      "2       0.191471   0.398940   0.409589\n",
      "3       0.155318   0.672025   0.172657\n",
      "4       0.229513   0.382841   0.387646\n",
      "...          ...        ...        ...\n",
      "7409    0.212339   0.339724   0.447936\n",
      "7410    0.244525   0.326957   0.428517\n",
      "7411    0.231022   0.534569   0.234408\n",
      "7412    0.209821   0.295674   0.494505\n",
      "7413    0.189348   0.401561   0.409092\n",
      "\n",
      "[7414 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "biogeme.createLogFile()\n",
    "\n",
    "results = biogeme.simulate()\n",
    "\n",
    "# Get the results in a pandas table\n",
    "#pandasResults = results.getEstimatedParameters()\n",
    "#print(pandasResults)\n",
    "\n",
    "\n",
    "print(\"Results=\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      simprob_sq  simprob_a  simprob_b  choice_simpre\n",
      "0       0.215018   0.437310   0.347672              2\n",
      "1       0.217412   0.385622   0.396966              3\n",
      "2       0.191471   0.398940   0.409589              3\n",
      "3       0.155318   0.672025   0.172657              2\n",
      "4       0.229513   0.382841   0.387646              3\n",
      "...          ...        ...        ...            ...\n",
      "7409    0.212339   0.339724   0.447936              3\n",
      "7410    0.244525   0.326957   0.428517              3\n",
      "7411    0.231022   0.534569   0.234408              2\n",
      "7412    0.209821   0.295674   0.494505              3\n",
      "7413    0.189348   0.401561   0.409092              3\n",
      "\n",
      "[7414 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "results.loc[(results['simprob_sq']>results['simprob_a']) & (results['simprob_sq']>results['simprob_b']),\"choice_simpre\"]=1\n",
    "results.loc[(results['simprob_a']>results['simprob_sq']) & (results['simprob_a']>results['simprob_b']),\"choice_simpre\"]=2\n",
    "results.loc[(results['simprob_b']>results['simprob_sq']) & (results['simprob_b']>results['simprob_a']),\"choice_simpre\"]=3\n",
    "results['choice_simpre'] = results['choice_simpre'].astype(int)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulation Accuracy :  0.4817912058268141\n",
      "simulation Accuracy :  0.4817912058268141\n"
     ]
    }
   ],
   "source": [
    "#a naive test w/o considering the panel structure\n",
    "y_simpredict = results['choice_simpre']  \n",
    "y_true= df.choice\n",
    "print(\"simulation Accuracy : \", accuracy_score(y_true, y_simpredict))\n",
    "print(\"simulation Accuracy : \", accuracy_score( y_simpredict,y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
